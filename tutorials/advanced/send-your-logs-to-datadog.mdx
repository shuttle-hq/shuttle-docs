---
title: "Building an Observability Dashboard with Datadog"
description: "Learn to integrate comprehensive logging and monitoring into your Rust applications using Shuttle's production-ready infrastructure"
icon: "telescope"
---

> This tutorial builds upon concepts from the original work by [Roberto Huertas](https://robertohuertas.com/), enhanced with Shuttle's Infrastructure from Code approach.

## Learning Objectives

By completing this tutorial, you'll master **Shuttle production observability** and learn to:

- **Shuttle Secrets Management**: Securely handle Datadog API keys and monitoring configuration
- **Production Logging**: Implement structured logging with automatic log forwarding
- **Infrastructure from Code**: Define observability patterns with Shuttle's runtime
- **Request Tracing**: Track user journeys with correlation IDs and distributed traces
- **Performance Monitoring**: Collect metrics, alerts, and real-time dashboards

## Prerequisites

- Completed [REST APIs with Axum](/tutorials/beginner/rest-http-service-with-axum) tutorial
- Understanding of HTTP APIs and JSON logging
- [Shuttle CLI installed](/getting-started/installation)
- [Datadog account](https://app.datadoghq.com/signup) (free trial available)

**Time Required**: 50-65 minutes

## What We're Building

We'll create **TaskFlow** - a production task management API with comprehensive observability:

- **Structured Logging** - JSON logs with contextual information and correlation IDs
- **Real-Time Monitoring** - Live log streaming to Datadog with custom metrics
- **Performance Tracking** - Request tracing, response times, and error rates
- **Production Alerts** - Automated monitoring and incident detection
- **Secure Configuration** - Shuttle secrets for API keys and environment settings

Users can manage tasks through a REST API while operators monitor performance, errors, and usage patterns in real-time.

## Tutorial Steps

### Step 1: Initialize Observability Project

Create a new monitored API project:

```bash
shuttle init --template axum taskflow
cd taskflow
```

Update `Cargo.toml` with observability dependencies:

```toml
[package]
name = "taskflow"
version = "0.1.0"
edition = "2021"

[dependencies]
# Shuttle infrastructure
shuttle-axum = "0.56.0"
shuttle-runtime = "0.56.0"
shuttle-secrets = "0.56.0"

# Web framework
axum = { version = "0.7", features = ["macros"] }
tower = "0.5"
tower-http = { version = "0.5", features = ["trace", "request-id", "cors"] }

# Structured logging and tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["json", "env-filter", "time"] }
tracing-appender = "0.2"

# Datadog integration
dd-tracing-layer = "0.2"
serde_json = "1.0"

# Data handling
serde = { version = "1.0", features = ["derive"] }
uuid = { version = "1.0", features = ["v4", "serde"] }
chrono = { version = "0.4", features = ["serde"] }
tokio = { version = "1.0", features = ["full"] }
```

### Step 2: Define Observability Models

Create `src/models.rs` with traceable data structures:

```rust
use serde::{Deserialize, Serialize};
use uuid::Uuid;
use chrono::{DateTime, Utc};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Task {
    pub id: Uuid,
    pub title: String,
    pub description: Option<String>,
    pub completed: bool,
    pub priority: Priority,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub version: u32, // For optimistic locking
}

#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum Priority {
    Low,
    Medium,
    High,
    Critical,
}

#[derive(Debug, Deserialize)]
pub struct CreateTask {
    pub title: String,
    pub description: Option<String>,
    pub priority: Option<Priority>,
}

#[derive(Debug, Deserialize)]
pub struct UpdateTask {
    pub title: Option<String>,
    pub description: Option<String>,
    pub completed: Option<bool>,
    pub priority: Option<Priority>,
}

// API Response types with tracing context
#[derive(Debug, Serialize)]
pub struct ApiResponse<T> {
    pub data: T,
    pub meta: ResponseMeta,
}

#[derive(Debug, Serialize)]
pub struct ResponseMeta {
    pub request_id: String,
    pub timestamp: DateTime<Utc>,
    pub version: &'static str,
}

#[derive(Debug, Serialize)]
pub struct ErrorResponse {
    pub error: ApiError,
    pub meta: ResponseMeta,
}

#[derive(Debug, Serialize)]
pub struct ApiError {
    pub code: String,
    pub message: String,
    pub details: Option<serde_json::Value>,
}

impl<T> ApiResponse<T> {
    pub fn success(data: T, request_id: String) -> Self {
        Self {
            data,
            meta: ResponseMeta {
                request_id,
                timestamp: Utc::now(),
                version: env!("CARGO_PKG_VERSION"),
            },
        }
    }
}

impl ErrorResponse {
    pub fn new(code: &str, message: &str, request_id: String) -> Self {
        Self {
            error: ApiError {
                code: code.to_string(),
                message: message.to_string(),
                details: None,
            },
            meta: ResponseMeta {
                request_id,
                timestamp: Utc::now(),
                version: env!("CARGO_PKG_VERSION"),
            },
        }
    }

    pub fn with_details(code: &str, message: &str, details: serde_json::Value, request_id: String) -> Self {
        Self {
            error: ApiError {
                code: code.to_string(),
                message: message.to_string(),
                details: Some(details),
            },
            meta: ResponseMeta {
                request_id,
                timestamp: Utc::now(),
                version: env!("CARGO_PKG_VERSION"),
            },
        }
    }
}

impl Default for Priority {
    fn default() -> Self {
        Priority::Medium
    }
}

// Application metrics for monitoring
#[derive(Debug, Clone)]
pub struct AppMetrics {
    pub requests_total: std::sync::Arc<std::sync::atomic::AtomicU64>,
    pub requests_errors: std::sync::Arc<std::sync::atomic::AtomicU64>,
    pub tasks_total: std::sync::Arc<std::sync::atomic::AtomicU64>,
    pub tasks_completed: std::sync::Arc<std::sync::atomic::AtomicU64>,
}

impl AppMetrics {
    pub fn new() -> Self {
        Self {
            requests_total: std::sync::Arc::new(std::sync::atomic::AtomicU64::new(0)),
            requests_errors: std::sync::Arc::new(std::sync::atomic::AtomicU64::new(0)),
            tasks_total: std::sync::Arc::new(std::sync::atomic::AtomicU64::new(0)),
            tasks_completed: std::sync::Arc::new(std::sync::atomic::AtomicU64::new(0)),
        }
    }

    pub fn increment_requests(&self) {
        self.requests_total.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
    }

    pub fn increment_errors(&self) {
        self.requests_errors.fetch_add(1, std::sync::atomic::Ordering::Relaxed);
    }

    pub fn update_task_stats(&self, total: u64, completed: u64) {
        self.tasks_total.store(total, std::sync::atomic::Ordering::Relaxed);
        self.tasks_completed.store(completed, std::sync::atomic::Ordering::Relaxed);
    }

    pub fn get_stats(&self) -> (u64, u64, u64, u64) {
        (
            self.requests_total.load(std::sync::atomic::Ordering::Relaxed),
            self.requests_errors.load(std::sync::atomic::Ordering::Relaxed),
            self.tasks_total.load(std::sync::atomic::Ordering::Relaxed),
            self.tasks_completed.load(std::sync::atomic::Ordering::Relaxed),
        )
    }
}

// In-memory storage with monitoring hooks
pub type TaskStore = std::sync::Arc<std::sync::RwLock<std::collections::HashMap<Uuid, Task>>>;
```

### Step 3: Configure Shuttle Observability Infrastructure

Create `src/observability.rs` for Shuttle-integrated monitoring:

```rust
use dd_tracing_layer::{DatadogOptions, Region};
use shuttle_secrets::SecretStore;
use tracing_subscriber::{layer::SubscriberExt, util::SubscriberInitExt, EnvFilter, Layer};
use tracing::{info, warn};

const SERVICE_NAME: &str = "taskflow";

pub fn setup_shuttle_observability(secrets: &SecretStore) -> Result<(), Box<dyn std::error::Error>> {
    // Get configuration from Shuttle secrets
    let datadog_api_key = secrets.get("DATADOG_API_KEY")
        .ok_or("DATADOG_API_KEY not found in Shuttle secrets")?;

    let environment = secrets.get("ENVIRONMENT")
        .unwrap_or_else(|| "production".to_string());

    let log_level = secrets.get("LOG_LEVEL")
        .unwrap_or_else(|| "INFO".to_string());

    let service_version = env!("CARGO_PKG_VERSION");

    // Create environment filter for log levels
    let env_filter = EnvFilter::try_new(&log_level)
        .map_err(|e| format!("Invalid log level '{}': {}", log_level, e))?;

    // Configure Datadog layer with Shuttle environment tags
    let datadog_tags = format!(
        "env:{},service:{},version:{},platform:shuttle,region:us1",
        environment, SERVICE_NAME, service_version
    );

    let datadog_layer = dd_tracing_layer::create(
        DatadogOptions::new(SERVICE_NAME, datadog_api_key)
            .with_region(Region::US1)
            .with_tags(datadog_tags)
            .with_hostname(format!("{}-{}", SERVICE_NAME, environment))
    );

    // Create structured JSON console layer for Shuttle logs
    let console_layer = tracing_subscriber::fmt::layer()
        .json()
        .flatten_event(true)
        .with_current_span(false)
        .with_span_list(false)
        .with_timer(tracing_subscriber::fmt::time::UtcTime::rfc_3339())
        .with_target(false)
        .with_file(false)
        .with_line_number(false)
        .with_filter(env_filter.clone());

    // Initialize multi-layer subscriber
    tracing_subscriber::registry()
        .with(console_layer)
        .with(datadog_layer.with_filter(env_filter))
        .init();

    info!(
        service = SERVICE_NAME,
        environment = environment,
        version = service_version,
        platform = "shuttle",
        "Observability infrastructure initialized"
    );

    Ok(())
}

// Extract or generate request ID for correlation
pub fn extract_request_id(headers: &axum::http::HeaderMap) -> String {
    headers
        .get("x-request-id")
        .and_then(|h| h.to_str().ok())
        .map(String::from)
        .unwrap_or_else(|| uuid::Uuid::new_v4().to_string())
}

// Structured context for request tracking
#[derive(Debug, Clone)]
pub struct RequestContext {
    pub request_id: String,
    pub user_agent: Option<String>,
    pub client_ip: Option<String>,
    pub method: String,
    pub path: String,
}

impl RequestContext {
    pub fn from_request(
        headers: &axum::http::HeaderMap,
        method: &axum::http::Method,
        uri: &axum::http::Uri,
    ) -> Self {
        let request_id = extract_request_id(headers);

        let user_agent = headers
            .get("user-agent")
            .and_then(|h| h.to_str().ok())
            .map(String::from);

        let client_ip = headers
            .get("x-forwarded-for")
            .or_else(|| headers.get("x-real-ip"))
            .and_then(|h| h.to_str().ok())
            .and_then(|ip| ip.split(',').next())
            .map(|ip| ip.trim().to_string());

        Self {
            request_id,
            user_agent,
            client_ip,
            method: method.to_string(),
            path: uri.path().to_string(),
        }
    }
}

// Performance timing utilities
pub struct Timer {
    start: std::time::Instant,
}

impl Timer {
    pub fn start() -> Self {
        Self {
            start: std::time::Instant::now(),
        }
    }

    pub fn elapsed_ms(&self) -> f64 {
        self.start.elapsed().as_secs_f64() * 1000.0
    }
}
```

### Step 4: Build Instrumented API Handlers

Create `src/handlers.rs` with comprehensive tracing:

```rust
use crate::{models::*, observability::*};
use axum::{
    extract::{Path, State},
    http::{HeaderMap, Method, StatusCode, Uri},
    response::Json,
};
use std::sync::Arc;
use tracing::{info, warn, error, instrument, Span};
use uuid::Uuid;

pub type AppState = (TaskStore, Arc<AppMetrics>);

#[instrument(
    skip(state, headers),
    fields(
        request_id = %context.request_id,
        endpoint = "create_task",
        method = %context.method,
        path = %context.path
    )
)]
pub async fn create_task(
    State((store, metrics)): State<AppState>,
    method: Method,
    uri: Uri,
    headers: HeaderMap,
    Json(create_task): Json<CreateTask>,
) -> Result<Json<ApiResponse<Task>>, (StatusCode, Json<ErrorResponse>)> {
    let context = RequestContext::from_request(&headers, &method, &uri);
    let timer = Timer::start();

    // Record span attributes
    Span::current().record("user_agent", context.user_agent.as_deref().unwrap_or("unknown"));
    Span::current().record("client_ip", context.client_ip.as_deref().unwrap_or("unknown"));

    metrics.increment_requests();

    // Validate input with detailed logging
    if create_task.title.trim().is_empty() {
        metrics.increment_errors();

        warn!(
            request_id = %context.request_id,
            validation_error = "empty_title",
            "Task creation failed: empty title provided"
        );

        return Err((
            StatusCode::BAD_REQUEST,
            Json(ErrorResponse::with_details(
                "validation_error",
                "Task title cannot be empty",
                serde_json::json!({
                    "field": "title",
                    "value": create_task.title,
                    "constraint": "non_empty"
                }),
                context.request_id,
            )),
        ));
    }

    // Create task with full audit trail
    let task = Task {
        id: Uuid::new_v4(),
        title: create_task.title.trim().to_string(),
        description: create_task.description,
        completed: false,
        priority: create_task.priority.unwrap_or_default(),
        created_at: chrono::Utc::now(),
        updated_at: chrono::Utc::now(),
        version: 1,
    };

    // Store with monitoring
    {
        let mut tasks = store.write().unwrap();
        tasks.insert(task.id, task.clone());

        let total_tasks = tasks.len() as u64;
        let completed_tasks = tasks.values().filter(|t| t.completed).count() as u64;
        drop(tasks);

        metrics.update_task_stats(total_tasks, completed_tasks);
    }

    let response_time = timer.elapsed_ms();

    info!(
        request_id = %context.request_id,
        task_id = %task.id,
        title = %task.title,
        priority = ?task.priority,
        response_time_ms = response_time,
        user_agent = context.user_agent.as_deref().unwrap_or("unknown"),
        "Task created successfully"
    );

    Ok(Json(ApiResponse::success(task, context.request_id)))
}

#[instrument(
    skip(state, headers),
    fields(
        request_id = %context.request_id,
        endpoint = "list_tasks",
        method = %context.method
    )
)]
pub async fn list_tasks(
    State((store, metrics)): State<AppState>,
    method: Method,
    uri: Uri,
    headers: HeaderMap,
) -> Json<ApiResponse<Vec<Task>>> {
    let context = RequestContext::from_request(&headers, &method, &uri);
    let timer = Timer::start();

    metrics.increment_requests();

    let tasks = {
        let tasks = store.read().unwrap();
        tasks.values().cloned().collect::<Vec<_>>()
    };

    let response_time = timer.elapsed_ms();

    info!(
        request_id = %context.request_id,
        task_count = tasks.len(),
        response_time_ms = response_time,
        "Tasks retrieved successfully"
    );

    Json(ApiResponse::success(tasks, context.request_id))
}

#[instrument(
    skip(state, headers),
    fields(
        request_id = %context.request_id,
        task_id = %task_id,
        endpoint = "get_task"
    )
)]
pub async fn get_task(
    Path(task_id): Path<Uuid>,
    State((store, metrics)): State<AppState>,
    method: Method,
    uri: Uri,
    headers: HeaderMap,
) -> Result<Json<ApiResponse<Task>>, (StatusCode, Json<ErrorResponse>)> {
    let context = RequestContext::from_request(&headers, &method, &uri);
    let timer = Timer::start();

    metrics.increment_requests();

    let task = {
        let tasks = store.read().unwrap();
        tasks.get(&task_id).cloned()
    };

    match task {
        Some(task) => {
            let response_time = timer.elapsed_ms();

            info!(
                request_id = %context.request_id,
                task_id = %task_id,
                title = %task.title,
                completed = task.completed,
                response_time_ms = response_time,
                "Task retrieved successfully"
            );

            Ok(Json(ApiResponse::success(task, context.request_id)))
        }
        None => {
            metrics.increment_errors();
            let response_time = timer.elapsed_ms();

            warn!(
                request_id = %context.request_id,
                task_id = %task_id,
                response_time_ms = response_time,
                "Task not found"
            );

            Err((
                StatusCode::NOT_FOUND,
                Json(ErrorResponse::new(
                    "not_found",
                    &format!("Task with ID {} not found", task_id),
                    context.request_id,
                )),
            ))
        }
    }
}

#[instrument(
    skip(state, headers),
    fields(
        request_id = %context.request_id,
        task_id = %task_id,
        endpoint = "update_task"
    )
)]
pub async fn update_task(
    Path(task_id): Path<Uuid>,
    State((store, metrics)): State<AppState>,
    method: Method,
    uri: Uri,
    headers: HeaderMap,
    Json(update): Json<UpdateTask>,
) -> Result<Json<ApiResponse<Task>>, (StatusCode, Json<ErrorResponse>)> {
    let context = RequestContext::from_request(&headers, &method, &uri);
    let timer = Timer::start();

    metrics.increment_requests();

    let result = {
        let mut tasks = store.write().unwrap();
        match tasks.get_mut(&task_id) {
            Some(task) => {
                let old_completed = task.completed;
                let old_title = task.title.clone();

                // Apply updates with validation
                if let Some(title) = &update.title {
                    if title.trim().is_empty() {
                        return Err((
                            StatusCode::BAD_REQUEST,
                            Json(ErrorResponse::new(
                                "validation_error",
                                "Task title cannot be empty",
                                context.request_id,
                            )),
                        ));
                    }
                    task.title = title.trim().to_string();
                }

                if let Some(description) = update.description {
                    task.description = Some(description);
                }

                if let Some(completed) = update.completed {
                    task.completed = completed;
                }

                if let Some(priority) = update.priority {
                    task.priority = priority;
                }

                task.updated_at = chrono::Utc::now();
                task.version += 1;

                let updated_task = task.clone();

                // Update metrics
                let total_tasks = tasks.len() as u64;
                let completed_tasks = tasks.values().filter(|t| t.completed).count() as u64;

                Ok((updated_task, old_completed, old_title, total_tasks, completed_tasks))
            }
            None => Err(()),
        }
    };

    match result {
        Ok((task, old_completed, old_title, total_tasks, completed_tasks)) => {
            metrics.update_task_stats(total_tasks, completed_tasks);
            let response_time = timer.elapsed_ms();

            info!(
                request_id = %context.request_id,
                task_id = %task_id,
                old_title = %old_title,
                new_title = %task.title,
                old_completed = old_completed,
                new_completed = task.completed,
                response_time_ms = response_time,
                "Task updated successfully"
            );

            Ok(Json(ApiResponse::success(task, context.request_id)))
        }
        Err(_) => {
            metrics.increment_errors();
            let response_time = timer.elapsed_ms();

            warn!(
                request_id = %context.request_id,
                task_id = %task_id,
                response_time_ms = response_time,
                "Task update failed: not found"
            );

            Err((
                StatusCode::NOT_FOUND,
                Json(ErrorResponse::new(
                    "not_found",
                    &format!("Task with ID {} not found", task_id),
                    context.request_id,
                )),
            ))
        }
    }
}

#[instrument(
    skip(state, headers),
    fields(
        request_id = %context.request_id,
        task_id = %task_id,
        endpoint = "delete_task"
    )
)]
pub async fn delete_task(
    Path(task_id): Path<Uuid>,
    State((store, metrics)): State<AppState>,
    method: Method,
    uri: Uri,
    headers: HeaderMap,
) -> Result<StatusCode, (StatusCode, Json<ErrorResponse>)> {
    let context = RequestContext::from_request(&headers, &method, &uri);
    let timer = Timer::start();

    metrics.increment_requests();

    let result = {
        let mut tasks = store.write().unwrap();
        match tasks.remove(&task_id) {
            Some(task) => {
                let total_tasks = tasks.len() as u64;
                let completed_tasks = tasks.values().filter(|t| t.completed).count() as u64;
                Ok((task, total_tasks, completed_tasks))
            }
            None => Err(()),
        }
    };

    match result {
        Ok((task, total_tasks, completed_tasks)) => {
            metrics.update_task_stats(total_tasks, completed_tasks);
            let response_time = timer.elapsed_ms();

            info!(
                request_id = %context.request_id,
                task_id = %task_id,
                title = %task.title,
                response_time_ms = response_time,
                total_tasks = total_tasks,
                "Task deleted successfully"
            );

            Ok(StatusCode::NO_CONTENT)
        }
        Err(_) => {
            metrics.increment_errors();
            let response_time = timer.elapsed_ms();

            warn!(
                request_id = %context.request_id,
                task_id = %task_id,
                response_time_ms = response_time,
                "Task deletion failed: not found"
            );

            Err((
                StatusCode::NOT_FOUND,
                Json(ErrorResponse::new(
                    "not_found",
                    &format!("Task with ID {} not found", task_id),
                    context.request_id,
                )),
            ))
        }
    }
}

#[instrument(
    skip(state, headers),
    fields(
        request_id = %context.request_id,
        endpoint = "health_check"
    )
)]
pub async fn health_check(
    State((_, metrics)): State<AppState>,
    method: Method,
    uri: Uri,
    headers: HeaderMap,
) -> Json<ApiResponse<serde_json::Value>> {
    let context = RequestContext::from_request(&headers, &method, &uri);
    let timer = Timer::start();

    let (total_requests, error_requests, total_tasks, completed_tasks) = metrics.get_stats();
    let error_rate = if total_requests > 0 {
        error_requests as f64 / total_requests as f64
    } else {
        0.0
    };

    let health_data = serde_json::json!({
        "status": "healthy",
        "timestamp": chrono::Utc::now(),
        "version": env!("CARGO_PKG_VERSION"),
        "service": "taskflow",
        "platform": "shuttle",
        "metrics": {
            "requests": {
                "total": total_requests,
                "errors": error_requests,
                "error_rate": error_rate
            },
            "tasks": {
                "total": total_tasks,
                "completed": completed_tasks,
                "completion_rate": if total_tasks > 0 { completed_tasks as f64 / total_tasks as f64 } else { 0.0 }
            }
        },
        "response_time_ms": timer.elapsed_ms()
    });

    info!(
        request_id = %context.request_id,
        total_requests = total_requests,
        error_rate = error_rate,
        total_tasks = total_tasks,
        "Health check performed"
    );

    Json(ApiResponse::success(health_data, context.request_id))
}
```

### Step 5: Configure Shuttle Secrets

Create `Secrets.toml` for production observability configuration:

```toml
DATADOG_API_KEY = "your_datadog_api_key_here"
ENVIRONMENT = "production"
LOG_LEVEL = "INFO"
```

For local development, create `Secrets.dev.toml`:

```toml
DATADOG_API_KEY = "your_datadog_api_key_here"
ENVIRONMENT = "development"
LOG_LEVEL = "DEBUG"
```

Add to `.gitignore`:

```bash
echo "Secrets*.toml" >> .gitignore
```

### Step 6: Wire Up the Complete Observability Stack

Update `src/main.rs` to create the production-ready application:

```rust
mod models;
mod observability;
mod handlers;

use crate::{
    handlers::*,
    models::*,
    observability::*,
};
use axum::{
    routing::{get, post, put, delete},
    Router,
};
use shuttle_secrets::SecretStore;
use std::{collections::HashMap, sync::{Arc, RwLock}};
use tower::ServiceBuilder;
use tower_http::{
    trace::TraceLayer,
    request_id::{MakeRequestId, PropagateRequestIdLayer, SetRequestIdLayer},
    cors::CorsLayer,
};
use tracing::{info, error};

// Custom request ID generator for correlation
#[derive(Clone)]
struct CustomMakeRequestId;

impl MakeRequestId for CustomMakeRequestId {
    fn make_request_id<B>(&mut self, _request: &axum::http::Request<B>) -> Option<axum::http::HeaderValue> {
        let request_id = uuid::Uuid::new_v4().to_string();
        axum::http::HeaderValue::from_str(&request_id).ok()
    }
}

#[shuttle_runtime::main]
async fn main(
    #[shuttle_secrets::Secrets] secrets: SecretStore,
) -> shuttle_axum::ShuttleAxum {
    // Initialize Shuttle observability infrastructure first
    if let Err(e) = setup_shuttle_observability(&secrets) {
        eprintln!("Failed to setup observability: {}", e);
        std::process::exit(1);
    }

    info!("ðŸš€ Starting TaskFlow API with comprehensive observability");

    // Initialize application state
    let task_store: TaskStore = Arc::new(RwLock::new(HashMap::new()));
    let app_metrics = Arc::new(AppMetrics::new());
    let app_state = (task_store, app_metrics);

    // Build comprehensive router with observability middleware
    let app = Router::new()
        // API routes
        .route("/api/tasks", get(list_tasks).post(create_task))
        .route("/api/tasks/:id", get(get_task).put(update_task).delete(delete_task))
        .route("/health", get(health_check))

        // Apply state
        .with_state(app_state)

        // Apply observability middleware stack
        .layer(
            ServiceBuilder::new()
                // CORS for web dashboards
                .layer(CorsLayer::permissive())

                // Request ID generation and propagation
                .layer(SetRequestIdLayer::x_request_id(CustomMakeRequestId))
                .layer(PropagateRequestIdLayer::x_request_id())

                // HTTP tracing
                .layer(TraceLayer::new_for_http())

                .into_inner(),
        );

    info!("âœ… TaskFlow API initialized with Datadog observability");
    info!("ðŸ“Š Health endpoint: /health");
    info!("ðŸ”— API endpoints: /api/tasks");

    Ok(app.into())
}
```

### Step 7: Get Your Datadog API Key

Set up Datadog integration:

1. Sign up at [Datadog](https://app.datadoghq.com/signup)
2. Navigate to **Organization Settings** â†’ **API Keys**
3. Create a new API key named "Shuttle TaskFlow"
4. Copy the key and update your `Secrets.toml` files

### Step 8: Test Your Observable API

Test locally with observability enabled:

```bash
shuttle run
```

Generate test traffic to see structured logs:

```bash
# Create tasks with different priorities
curl -X POST "http://localhost:8000/api/tasks" \
  -H "Content-Type: application/json" \
  -H "X-Request-ID: test-create-high-001" \
  -d '{"title": "Critical Bug Fix", "priority": "critical"}'

curl -X POST "http://localhost:8000/api/tasks" \
  -H "Content-Type: application/json" \
  -H "X-Request-ID: test-create-medium-002" \
  -d '{"title": "Feature Development", "priority": "medium"}'

# List all tasks
curl "http://localhost:8000/api/tasks" \
  -H "X-Request-ID: test-list-003"

# Check health and metrics
curl "http://localhost:8000/health" \
  -H "X-Request-ID: test-health-004"

# Test error handling
curl -X POST "http://localhost:8000/api/tasks" \
  -H "Content-Type: application/json" \
  -H "X-Request-ID: test-error-005" \
  -d '{"title": ""}'

curl "http://localhost:8000/api/tasks/non-existent-id" \
  -H "X-Request-ID: test-error-006"
```

### Step 9: Deploy to Production with Monitoring

Deploy your observable API:

```bash
shuttle deploy
```

Generate production traffic for monitoring:

```bash
# Replace with your deployed URL
export API_URL="https://taskflow.shuttle.app"

# Create test workload
for i in {1..10}; do
  curl -X POST "$API_URL/api/tasks" \
    -H "Content-Type: application/json" \
    -H "X-Request-ID: load-test-$i" \
    -d "{\"title\": \"Production Task $i\", \"priority\": \"medium\"}"

  sleep 0.5
done

# Test read performance
for i in {1..20}; do
  curl "$API_URL/api/tasks" \
    -H "X-Request-ID: read-test-$i"
  sleep 0.2
done

# Test error scenarios
curl -X POST "$API_URL/api/tasks" \
  -H "Content-Type: application/json" \
  -d '{"title": ""}'

curl "$API_URL/api/tasks/invalid-uuid"

# Monitor health
curl "$API_URL/health"
```

### Step 10: Set Up Datadog Dashboards

Create monitoring dashboards in Datadog:

**Key Log Queries:**

```
# View all TaskFlow logs
service:taskflow

# Monitor errors and warnings
service:taskflow (status:error OR status:warn)

# Track specific request flows
service:taskflow @request_id:"test-create-high-001"

# Monitor task operations
service:taskflow @endpoint:(create_task OR update_task OR delete_task)

# Performance monitoring
service:taskflow @response_time_ms:>100
```

**Create Dashboard Widgets:**

1. **Request Volume**: `count(service:taskflow) by endpoint`
2. **Error Rate**: `count(service:taskflow status:error) / count(service:taskflow)`
3. **Response Times**: `avg(service:taskflow @response_time_ms) by endpoint`
4. **Task Metrics**: `max(service:taskflow @total_tasks)`

**Set Up Alerts:**

- Error rate > 5% in 5 minutes
- Response time P95 > 500ms
- No logs for 5 minutes (service down)

## What You've Learned

You've successfully built a production-ready observability stack and mastered:

### Shuttle Observability Patterns

- **Secrets Management** with `#[shuttle_secrets::Secrets]` for secure API key handling
- **Infrastructure from Code** with declarative observability configuration
- **Production Logging** with structured JSON logs and automatic forwarding
- **Request Correlation** with automatic ID generation and propagation

### Advanced Monitoring Techniques

- **Distributed Tracing** with span instrumentation and context propagation
- **Custom Metrics** for business logic monitoring and alerting
- **Error Tracking** with structured error responses and classification
- **Performance Monitoring** with response times and throughput tracking

### Production Deployment Practices

- **Environment Configuration** with separate development and production settings
- **Real-Time Dashboards** for operational visibility and incident response
- **Automated Alerting** for proactive monitoring and SLA management
- **Correlation Analysis** for debugging complex distributed systems

## Troubleshooting

**Logs not appearing in Datadog?**

- Verify `DATADOG_API_KEY` in `Secrets.toml` is correct and active
- Check Datadog region settings match your account (US1/EU1)
- Ensure network connectivity from Shuttle deployment environment
- Review service name and tag configuration

**Request IDs not correlating?**

- Confirm `X-Request-ID` headers are being set by clients
- Verify middleware order in the ServiceBuilder stack
- Check that request context extraction is working properly

**High memory usage with logging?**

- Use appropriate log levels (`INFO` in production, `DEBUG` only when needed)
- Consider async logging for high-throughput applications
- Monitor structured data size in log events

**Missing performance metrics?**

- Ensure timer measurements are being recorded correctly
- Verify span instrumentation covers all critical code paths
- Check that metrics are being aggregated properly across requests

## Next Steps

Enhance your observability stack with advanced features:

1. **Distributed Tracing** - Connect traces across multiple services ([Multi-Service Tutorial](/tutorials/advanced/custom-service))
2. **Custom Dashboards** - Build service-specific monitoring interfaces
3. **SLO Monitoring** - Track service level objectives and error budgets
4. **Log Analysis** - Implement log-based alerting and anomaly detection
5. **Performance Profiling** - Add CPU and memory profiling for optimization

Your TaskFlow API demonstrates how Shuttle simplifies production observability with secure secrets management and zero-configuration infrastructure!

## Complete Code

Find the complete working code for this tutorial in our [examples repository](https://github.com/shuttle-hq/shuttle-examples/tree/main/observability-datadog).
